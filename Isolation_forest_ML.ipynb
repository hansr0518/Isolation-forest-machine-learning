{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import seed\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load & PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize global variable \n",
    "train_data = None #train1~23\n",
    "phase1_test_normal = None #test01,02,03\n",
    "phase1_test_abnormal = None #test_abn1,abn2\n",
    "phase2_final_normal = None #final01_label = 0\n",
    "phase2_final_abnormal = None  #fianl01_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate f1 value\n",
    "def acc_f1(y_true, y_pred, abnormal = 0):\n",
    "    cm = np.zeros((2,2))\n",
    "    cm[0][0] = np.sum((y_true != abnormal)&(y_pred != abnormal))\n",
    "    cm[0][1] = np.sum((y_true != abnormal)&(y_pred == abnormal))\n",
    "    cm[1][0] = np.sum((y_true == abnormal)&(y_pred != abnormal))\n",
    "    cm[1][1] = np.sum((y_true == abnormal)&(y_pred == abnormal))\n",
    "    precision = cm[1][1] / np.sum(cm[:,1])\n",
    "    recall = cm[1][1] / np.sum(cm[1,:])\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    return (cm[0][0] + cm[1][1])/(np.sum(cm)), f1\n",
    "\n",
    "# calculate iou value\n",
    "def IOU(y_true, y_pred, abnormal = 0):\n",
    "    U = np.sum((y_true == abnormal)|(y_pred == abnormal))\n",
    "    I = np.sum((y_true == abnormal)&(y_pred == abnormal))\n",
    "    return I/U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "def nor(data, interval, strides):\n",
    "    data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "    data_norm = data_norm.fillna(0)\n",
    "    X_data = []\n",
    "    for i in range(0, data_norm.shape[0], strides):\n",
    "        temp = data_norm.iloc[i:i+interval].values\n",
    "        if temp.shape[0] != interval:\n",
    "            continue\n",
    "        X_data.append(np.expand_dims(temp, axis=0))\n",
    "    X_data = np.concatenate(X_data, axis=0)\n",
    "    print(X_data.shape)\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data accumulation\n",
    "# delete 3 meaningless columns \n",
    "def file_concat(input_path):\n",
    "    global train_data, phase1_test_normal, phase1_test_abnormal \n",
    "    for input_file in sorted(glob.glob(os.path.join(input_path,'*.csv'))):\n",
    "        print(input_file)\n",
    "        data = pd.read_csv(input_file)\n",
    "        data = data.iloc[:,1:]\n",
    "        if 'final' not in input_file:\n",
    "            data = data.drop(['sensor_smk','sensor_air','sensor_cycle'], axis=1)\n",
    "        if 'train' in input_file:\n",
    "            if train_data is None :\n",
    "                train_data = data\n",
    "                print(train_data.shape)\n",
    "            else:\n",
    "                train_data = np.concatenate([train_data, data], axis=0)\n",
    "                print(train_data.shape)\n",
    "        if 'test' in input_file:\n",
    "            if ('_' not in input_file):\n",
    "                if phase1_test_normal is None :\n",
    "                    phase1_test_normal = data\n",
    "                    print(phase1_test_normal.shape)\n",
    "                else:\n",
    "                    phase1_test_normal = np.concatenate([phase1_test_normal, data], axis=0)\n",
    "                    print(phase1_test_normal.shape)\n",
    "            else:\n",
    "                if phase1_test_abnormal is None :\n",
    "                    phase1_test_abnormal = data\n",
    "                    print(phase1_test_abnormal.shape)\n",
    "                else:\n",
    "                    phase1_test_abnormal = np.concatenate([phase1_test_abnormal, data], axis=0)\n",
    "                    print(phase1_test_abnormal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../problem1/test01.csv\n",
      "(79032, 108)\n",
      "./../../problem1/test01_PCR.csv\n",
      "(16342, 108)\n",
      "./../../problem1/test02.csv\n",
      "(128043, 108)\n",
      "./../../problem1/test02_smkLim.csv\n",
      "(33374, 108)\n",
      "./../../problem1/test03.csv\n",
      "(176071, 108)\n",
      "./../../problem1/train01.csv\n",
      "(86058, 108)\n",
      "./../../problem1/train02.csv\n",
      "(172839, 108)\n",
      "./../../problem1/train03.csv\n",
      "(225630, 108)\n",
      "./../../problem1/train04.csv\n",
      "(312409, 108)\n",
      "./../../problem1/train05.csv\n",
      "(389259, 108)\n",
      "./../../problem1/train06.csv\n",
      "(480356, 108)\n",
      "./../../problem1/train07.csv\n",
      "(544137, 108)\n",
      "./../../problem1/train08.csv\n",
      "(550518, 108)\n",
      "./../../problem1/train09.csv\n",
      "(573715, 108)\n",
      "./../../problem1/train10.csv\n",
      "(645708, 108)\n",
      "./../../problem1/train11.csv\n",
      "(689912, 108)\n",
      "./../../problem1/train12.csv\n",
      "(743932, 108)\n",
      "./../problem1/final01.csv\n",
      "./../problem1/final_label.csv\n",
      "./../problem1/train13.csv\n",
      "(791564, 108)\n",
      "./../problem1/train14.csv\n",
      "(798129, 108)\n",
      "./../problem1/train15.csv\n",
      "(824643, 108)\n",
      "./../problem1/train16.csv\n",
      "(837563, 108)\n",
      "./../problem1/train17.csv\n",
      "(891065, 108)\n",
      "./../problem1/train18.csv\n",
      "(913589, 108)\n",
      "./../problem1/train19.csv\n",
      "(927283, 108)\n",
      "./../problem1/train20.csv\n",
      "(937503, 108)\n",
      "./../problem1/train21.csv\n",
      "(981707, 108)\n",
      "./../problem1/train22.csv\n",
      "(1035727, 108)\n",
      "./../problem1/train23.csv\n",
      "(1043638, 108)\n"
     ]
    }
   ],
   "source": [
    "file_concat('./../../problem1/')\n",
    "file_concat('./../problem1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame formation\n",
    "train=pd.DataFrame(train_data)\n",
    "test_a=pd.DataFrame(phase1_test_normal)\n",
    "ab_a=pd.DataFrame(phase1_test_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data read , label = 1 --> abnormal\n",
    "dt_final = pd.read_csv('./../problem1/final01.csv')\n",
    "dt_final = dt_final.iloc[:,1:]\n",
    "dt_label = pd.read_csv('./../problem1/final_label.csv', header=None, names=['final_label'])\n",
    "X_data_fin_test = pd.concat([dt_final, dt_label], axis=1)\n",
    "X_data_fin_test = X_data_fin_test.drop(['sensor_smk','sensor_air','sensor_cycle'], axis=1)\n",
    "phase2_final_normal=X_data_fin_test[X_data_fin_test['final_label'] ==0.0].iloc[:,:].drop(['final_label'], axis = 1)\n",
    "phase2_final_abnormal=X_data_fin_test[X_data_fin_test['final_label'] ==1.0].iloc[:,:].drop(['final_label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521815, 10, 108)\n",
      "(88031, 10, 108)\n",
      "(16683, 10, 108)\n",
      "(5414, 10, 108)\n",
      "(5266, 10, 108)\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "strides = 2\n",
    "\n",
    "train_a=nor(train, interval, strides)\n",
    "test_b=nor(test_a, interval, strides)\n",
    "ab_b=nor(ab_a, interval, strides)\n",
    "phase2_final_normal=nor(phase2_final_normal, interval, strides)\n",
    "phase2_final_abnormal=nor(phase2_final_abnormal, interval, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n= train_a\n",
    "test_n= test_b\n",
    "ab_n= ab_b\n",
    "p2_test_n = phase2_final_normal\n",
    "p2_ab_n = phase2_final_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((521815, 10, 108),\n",
       " (88031, 10, 108),\n",
       " (16683, 10, 108),\n",
       " (5414, 10, 108),\n",
       " (5266, 10, 108))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n.shape, test_n.shape, ab_n.shape, p2_test_n.shape, p2_ab_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  isoloation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions=64\n",
    "timesteps=10\n",
    "input_dim=train_a.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((521815, 10, 108),\n",
       " (88031, 10, 108),\n",
       " (16683, 10, 108),\n",
       " (5414, 10, 108),\n",
       " (5266, 10, 108))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n.shape, test_n.shape, ab_n.shape, p2_test_n.shape, p2_ab_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm encoder 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.engine.training.Model at 0x7f4a97779a90>,\n",
       " <keras.engine.training.Model at 0x7f4a978ce390>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using auto encoder for the best optimization\n",
    "def get_model(x):\n",
    "    inputs = Input(shape=(timesteps, input_dim))\n",
    "    encoded = LSTM(n_dimensions, return_sequences=False, name=\"encoder\")(inputs)\n",
    "    decoded = RepeatVector(timesteps)(encoded)\n",
    "    decoded = LSTM(input_dim, return_sequences=True, name='decoder')(decoded)\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    return autoencoder, encoder\n",
    "\n",
    "get_model(train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "521815/521815 [==============================] - 42s 81us/step - loss: 0.0035 - acc: 0.1654 - cosine_proximity: -0.9928\n",
      "Epoch 2/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0012 - acc: 0.2402 - cosine_proximity: -0.9981\n",
      "Epoch 3/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0011 - acc: 0.2801 - cosine_proximity: -0.9982\n",
      "Epoch 4/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0011 - acc: 0.2746 - cosine_proximity: -0.9983\n",
      "Epoch 5/10\n",
      "521815/521815 [==============================] - 41s 79us/step - loss: 0.0011 - acc: 0.2546 - cosine_proximity: -0.9984\n",
      "Epoch 6/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0011 - acc: 0.2363 - cosine_proximity: -0.9984\n",
      "Epoch 7/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0010 - acc: 0.2387 - cosine_proximity: -0.9985\n",
      "Epoch 8/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0010 - acc: 0.2390 - cosine_proximity: -0.9985\n",
      "Epoch 9/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 0.0010 - acc: 0.2357 - cosine_proximity: -0.9986\n",
      "Epoch 10/10\n",
      "521815/521815 [==============================] - 41s 78us/step - loss: 9.9110e-04 - acc: 0.2325 - cosine_proximity: -0.9986\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "autoencoder, encoder = get_model(n_dimensions)\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse', \n",
    "                    metrics=['acc', 'cosine_proximity'])\n",
    "\n",
    "history = autoencoder.fit(train_a, train_a, batch_size=500, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encoder.predict(train_a)\n",
    "encoded_test = encoder.predict(test_b)\n",
    "encoded_ab = encoder.predict(ab_b)\n",
    "# final means validation data set\n",
    "encoded_final_test = encoder.predict(phase2_final_normal)\n",
    "encoded_final_ab = encoder.predict(phase2_final_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./encoded_train_0726', encoded_train)\n",
    "# encoded_train = np.load('./encoded_train_0726.npy')\n",
    "# np.save('./encoded_test_0726', encoded_test)\n",
    "# encoded_test = np.load('./encoded_test_0726.npy')\n",
    "# np.save('./encoded_ab_0726', encoded_ab)\n",
    "# encoded_ab = np.load('./encoded_ab_0726.npy')\n",
    "# np.save('./encoded_final_test_0726', encoded_final_test)\n",
    "# encoded_final_test = np.load('./encoded_final_test_0726.npy')\n",
    "# np.save('./encoded_final_ab_0726', encoded_final_ab)\n",
    "# encoded_final_ab = np.load('./encoded_final_ab_0726.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((521815, 64), (88031, 64), (16683, 64), (5414, 64), (5266, 64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train.shape, encoded_test.shape, encoded_ab.shape, encoded_final_test.shape, encoded_final_ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81427548\n"
     ]
    }
   ],
   "source": [
    "clf=IsolationForest(contamination=0.038, random_state=16, n_jobs=-1, behaviour= \"new\", max_features=32, max_samples=64)\n",
    "clf.fit(encoded_train)\n",
    "#phase 1 -> acc\n",
    "pred_test = clf.predict(encoded_test)\n",
    "pred_abnor= clf.predict(encoded_ab)\n",
    "\n",
    "pred_if = np.concatenate([pred_test, pred_abnor], axis=0)\n",
    "Y_data_if = np.array([1] * encoded_test.shape[0] + [-1] * encoded_ab.shape[0])\n",
    "result_if = acc_f1(Y_data_if, pred_if, abnormal = -1)\n",
    "\n",
    "#phase 2  -> iou\n",
    "pred_fin_test = clf.predict(encoded_final_test)\n",
    "pred_fin_abnor= clf.predict(encoded_final_ab)\n",
    "\n",
    "pred_iou = np.concatenate([pred_fin_test, pred_fin_abnor], axis=0)\n",
    "Y_data_iou = np.array([1] * encoded_final_test.shape[0] + [-1] * encoded_final_ab.shape[0])\n",
    "\n",
    "result_IOU = IOU(Y_data_iou, pred_iou, abnormal = -1)\n",
    "\n",
    "#print(\"Accuracy: %.8f\"%((result_if[0]+result_if[1])/2))\n",
    "#print(\"IOU: %.8f\"%(result_IOU))\n",
    "print(\"Accuracy: %.8f\"%((((result_if[0]+result_if[1])/2)+(result_IOU))/2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
